{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"w1vmGH99dO28"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/gdrive')\n","%cd /gdrive/My Drive/Colab Notebooks/AN2DL/Homework1"]},{"cell_type":"markdown","metadata":{"id":"Yh_62reFfKhd"},"source":["# Import libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c9rX-OacfHNM"},"outputs":[],"source":["import numpy as np\n","import os\n","import random\n","import pandas as pd\n","\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","%config InlineBackend.figure_format='retina'\n","plt.style.use('ggplot')\n","\n","from pathlib import Path\n","\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n","from sklearn.metrics import confusion_matrix\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from keras import layers\n","from keras.models import Model\n","\n","from pathlib import Path\n","\n","tfk = tf.keras\n","tfkl = tf.keras.layers\n","print(tf.__version__)"]},{"cell_type":"markdown","metadata":{"id":"a32c5609-54dc-44dc-a551-dd5e03e0448e"},"source":["# Global settings and seed"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"29ca5f27-ff4e-431e-94b8-b204be8e912b"},"outputs":[],"source":["IMAGE_SHAPE = [96,96]\n","INPUT_SHAPE = (*IMAGE_SHAPE,3)\n","BATCH_SIZE = 16\n","SEED = 42\n","DATASET_DIR = Path() / 'training_data_final'\n","EPOCHS = 30\n","\n","tf.random.set_seed(SEED)"]},{"cell_type":"markdown","metadata":{"id":"989ff936-2b06-4b62-a820-cc7d606fba56"},"source":["# Instantiate the dataset generators\n","\n","\n","Create two generators, one for training and one for validation.\n","It should be more correct to create one generator only and select `subset='training'` and `subset='validation'`, but in this way augmentation is applied to both sets. I prefer to create [two generators with the same split and the same seed.](https://stackoverflow.com/questions/71744605/keras-imagedatagenerator-validation-split-does-not-split-validation-data-as-expe)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bf808f9d-9906-4cb2-ab1c-c52b6a14d711"},"outputs":[],"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","# train generator with augmentation\n","train_image_gen  = ImageDataGenerator(rotation_range=40,\n","                                      width_shift_range=0.2,\n","                                      height_shift_range=0.2,\n","                                      zoom_range=[0.5,1.5],\n","                                      brightness_range=[0.5,1.5],\n","                                      shear_range=0.2,\n","                                      vertical_flip=True,\n","                                      horizontal_flip=True,\n","                                      fill_mode='reflect',\n","                                      validation_split = 0.15,\n","                                      )\n","\n","# validation generator without augmentation\n","validation_image_gen = ImageDataGenerator(validation_split = 0.15)\n","\n","train_dataset = train_image_gen.flow_from_directory(directory=DATASET_DIR,\n","                                                    target_size=IMAGE_SHAPE,\n","                                                    color_mode='rgb',\n","                                                    classes=None,\n","                                                    class_mode='categorical',\n","                                                    batch_size=BATCH_SIZE,\n","                                                    shuffle=True,\n","                                                    seed=SEED,\n","                                                    subset='training',\n","                                                    )\n","\n","validation_dataset = validation_image_gen.flow_from_directory(directory=DATASET_DIR,\n","                                                              target_size=IMAGE_SHAPE,\n","                                                              color_mode='rgb',\n","                                                              classes=None,\n","                                                              class_mode='categorical',\n","                                                              batch_size=BATCH_SIZE,\n","                                                              shuffle=False,\n","                                                              seed=SEED,\n","                                                              subset='validation'\n","                                                              )"]},{"cell_type":"code","source":["OUTPUT_DIR = Path() / 'supernet_histories'\n","OUTPUT_DIR.mkdir(parents=True, exist_ok=True)"],"metadata":{"id":"YmVCB7RIITIq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"350089c3-8553-4783-9976-2abd782d17bd"},"source":["# Supernet: VGG16"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d740ebdc-9522-4f26-9ebb-99c8d37f5492"},"outputs":[],"source":["vgg16  = keras.applications.vgg16.VGG16(\n","    weights='imagenet',\n","    include_top=False,\n","    input_shape=(224, 224,3)\n",")\n","vgg16.trainable = False"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6ea331eb-c123-4196-803c-c124ca78a5d3"},"outputs":[],"source":["inputs = keras.Input(shape=INPUT_SHAPE)\n","\n","x = layers.Resizing(224, 224, interpolation='bicubic', name='resizing')(inputs)\n","x = keras.applications.vgg16.preprocess_input(x)\n","x = vgg16(x)\n","\n","x = layers.GlobalAveragePooling2D()(x)\n","x = layers.Dense(512, kernel_initializer=keras.initializers.HeUniform(seed=SEED))(x)\n","x = layers.BatchNormalization()(x)\n","x = layers.Activation('relu')(x)\n","x = layers.Dropout(0.5)(x)\n","\n","outputs = layers.Dense(8, activation='softmax', kernel_initializer=keras.initializers.GlorotUniform(seed=SEED))(x)\n","\n","model_vgg16 = keras.Model(inputs, outputs)\n","\n","chosen_opt = keras.optimizers.Adam(learning_rate=1e-3)\n","model_vgg16.compile(loss=keras.losses.CategoricalCrossentropy(), optimizer=chosen_opt, metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oM6a_qwhiZFe"},"outputs":[],"source":["history_VGG16 = model_vgg16.fit(train_dataset, epochs=EPOCHS, validation_data=validation_dataset, verbose=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LKy2EvTqDrf0"},"outputs":[],"source":["np.save(str(OUTPUT_DIR / 'history_VGG16.npy'), history_VGG16.history)"]},{"cell_type":"markdown","metadata":{"id":"GyPTeNK_Aebt"},"source":["# Supernet: Xception"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jM6GWHDQAebu"},"outputs":[],"source":["Xception  = keras.applications.Xception(\n","    weights='imagenet',\n","    include_top=False,\n","    input_shape=(299, 299,3)\n",")\n","Xception.trainable = False"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T98FWRIdAebw"},"outputs":[],"source":["inputs = keras.Input(shape=INPUT_SHAPE)\n","\n","x = layers.Resizing(299, 299, interpolation='bicubic', name='resizing')(inputs)\n","x = keras.applications.xception.preprocess_input(x)\n","x = Xception(x)\n","\n","x = layers.GlobalAveragePooling2D()(x)\n","x = layers.Dense(512, kernel_initializer=keras.initializers.HeUniform(seed=SEED))(x)\n","x = layers.BatchNormalization()(x)\n","x = layers.Activation('relu')(x)\n","x = layers.Dropout(0.5)(x)\n","\n","outputs = layers.Dense(8, activation='softmax', kernel_initializer=keras.initializers.GlorotUniform(seed=SEED))(x)\n","\n","model_Xception = keras.Model(inputs, outputs)\n","\n","chosen_opt = keras.optimizers.Adam(learning_rate=1e-3)\n","model_Xception.compile(loss=keras.losses.CategoricalCrossentropy(), optimizer=chosen_opt, metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iF24CpRWAebx"},"outputs":[],"source":["history_Xception = model_Xception.fit(train_dataset, epochs=EPOCHS, validation_data=validation_dataset, verbose=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dJ-G8bEoGIWZ"},"outputs":[],"source":["np.save(str(OUTPUT_DIR / 'history_Xception.npy'), history_Xception.history)"]},{"cell_type":"markdown","metadata":{"id":"ZqORS1bYGMCB"},"source":["# Supernet: EfficientNetB0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"78VyiNdJGMCC"},"outputs":[],"source":["EfficientNetB0  = keras.applications.EfficientNetB0(\n","    weights='imagenet',\n","    include_top=False,\n","    input_shape=(224, 224,3)\n",")\n","EfficientNetB0.trainable = False"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"As3l5TJAGMCD"},"outputs":[],"source":["inputs = keras.Input(shape=INPUT_SHAPE)\n","\n","x = layers.Resizing(224, 224, interpolation='bicubic', name='resizing')(inputs)\n","x = keras.applications.efficientnet.preprocess_input(x)\n","x = EfficientNetB0(x)\n","\n","x = layers.GlobalAveragePooling2D()(x)\n","x = layers.Dense(512, kernel_initializer=keras.initializers.HeUniform(seed=SEED))(x)\n","x = layers.BatchNormalization()(x)\n","x = layers.Activation('relu')(x)\n","x = layers.Dropout(0.5)(x)\n","\n","outputs = layers.Dense(8, activation='softmax', kernel_initializer=keras.initializers.GlorotUniform(seed=SEED))(x)\n","\n","model_EfficientNetB0 = keras.Model(inputs, outputs)\n","\n","chosen_opt = keras.optimizers.Adam(learning_rate=1e-3)\n","model_EfficientNetB0.compile(loss=keras.losses.CategoricalCrossentropy(), optimizer=chosen_opt, metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"94xS_qLFGMCE"},"outputs":[],"source":["history_EfficientNetB0 = model_EfficientNetB0.fit(train_dataset, epochs=EPOCHS, validation_data=validation_dataset, verbose=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zvtdgkI0GMCE"},"outputs":[],"source":["np.save(str(OUTPUT_DIR / 'history_EfficientNetB0.npy'), history_EfficientNetB0.history)"]},{"cell_type":"markdown","metadata":{"id":"IxrfN_GzKCpe"},"source":["# Supernet: EfficientNetB7"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KSSm2dvTKCpf"},"outputs":[],"source":["EfficientNetB7  = keras.applications.EfficientNetB7(\n","    weights='imagenet',\n","    include_top=False,\n","    input_shape=(224, 224,3)\n",")\n","EfficientNetB7.trainable = False"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ki5XIADZKCpg"},"outputs":[],"source":["inputs = keras.Input(shape=INPUT_SHAPE)\n","\n","x = layers.Resizing(224, 224, interpolation='bicubic', name='resizing')(inputs)\n","x = keras.applications.efficientnet.preprocess_input(x)\n","x = EfficientNetB7(x)\n","\n","x = layers.GlobalAveragePooling2D()(x)\n","x = layers.Dense(512, kernel_initializer=keras.initializers.HeUniform(seed=SEED))(x)\n","x = layers.BatchNormalization()(x)\n","x = layers.Activation('relu')(x)\n","x = layers.Dropout(0.5)(x)\n","\n","outputs = layers.Dense(8, activation='softmax', kernel_initializer=keras.initializers.GlorotUniform(seed=SEED))(x)\n","\n","model_EfficientNetB7 = keras.Model(inputs, outputs)\n","\n","chosen_opt = keras.optimizers.Adam(learning_rate=1e-3)\n","model_EfficientNetB7.compile(loss=keras.losses.CategoricalCrossentropy(), optimizer=chosen_opt, metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vTcSpFEoKCpi"},"outputs":[],"source":["history_EfficientNetB7 = model_EfficientNetB7.fit(train_dataset, epochs=EPOCHS, validation_data=validation_dataset, verbose=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TlGRmUtqKCpi"},"outputs":[],"source":["np.save(str(OUTPUT_DIR / 'history_EfficientNetB7.npy'), history_EfficientNetB7.history)"]},{"cell_type":"markdown","metadata":{"id":"JhdRhahFHyiA"},"source":["# Supernet: ResNet-50"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"44fnXJRNHyiB"},"outputs":[],"source":["ResNet50  = keras.applications.ResNet50(\n","    weights='imagenet',\n","    include_top=False,\n","    input_shape=(224, 224,3)\n",")\n","ResNet50.trainable = False"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I2yUbfMBHyiC"},"outputs":[],"source":["inputs = keras.Input(shape=INPUT_SHAPE)\n","\n","x = layers.Resizing(224, 224, interpolation='bicubic', name='resizing')(inputs)\n","x = keras.applications.resnet.preprocess_input(x)\n","x = ResNet50(x)\n","\n","x = layers.GlobalAveragePooling2D()(x)\n","x = layers.Dense(512, kernel_initializer=keras.initializers.HeUniform(seed=SEED))(x)\n","x = layers.BatchNormalization()(x)\n","x = layers.Activation('relu')(x)\n","x = layers.Dropout(0.5)(x)\n","\n","outputs = layers.Dense(8, activation='softmax', kernel_initializer=keras.initializers.GlorotUniform(seed=SEED))(x)\n","\n","model_ResNet50 = keras.Model(inputs, outputs)\n","\n","chosen_opt = keras.optimizers.Adam(learning_rate=1e-3)\n","model_ResNet50.compile(loss=keras.losses.CategoricalCrossentropy(), optimizer=chosen_opt, metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O7VeChAMHyiD"},"outputs":[],"source":["history_ResNet50 = model_ResNet50.fit(train_dataset, epochs=EPOCHS, validation_data=validation_dataset, verbose=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EH9GDRFPHyiE"},"outputs":[],"source":["np.save(str(OUTPUT_DIR / 'history_ResNet-50.npy'), history_ResNet50.history)"]},{"cell_type":"markdown","metadata":{"id":"P4UukMnTF2Rj"},"source":["# Final Plot "]},{"cell_type":"markdown","source":["Read the history."],"metadata":{"id":"Wv6zt42QJbjO"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"c2obzZgptAT-"},"outputs":[],"source":["names = ['VGG16', 'Xception', 'EfficientNetB0', 'EfficientNetB7', 'ResNet-50']\n","history = list()\n","for i in names:\n","    name = OUTPUT_DIR / 'history_'+i+'.npy'\n","    history.append(np.load(name, allow_pickle='TRUE').item())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IDG0o2cXw4q8"},"outputs":[],"source":["# Two subplots, the axes array is 1-d\n","fig, (ax1,ax2) = plt.subplots(2, sharex=True)\n","\n","#fig.suptitle('Results with different supernets')\n","\n","for i in range(0,len(names)):\n","  ax1.plot(history[i]['val_accuracy'], label=names[i])\n","\n","ax1.set_ylabel('Accuracy')\n","ax1.set_xlabel('Epochs')\n","ax1.legend(loc='upper left')\n","\n","for i in range(0,len(names)):\n","  ax2.plot(history[i]['val_loss'], label=names[i])\n","\n","ax2.set_ylabel('Loss')\n","ax2.set_xlabel('Epochs')\n","ax2.legend(loc='upper left')\n","\n","plt.savefig(str(Path() / 'report_material' / 'supernet.pdf'), bbox_inches='tight')\n","plt.show()"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}